## Tasks
[ ] Create a python producer to mock a continuous producer of the data (like CPU data, or  Memory utilisation, Network rate)
[ ] Build a python consumer to consume data from kafka stream, analysing and outputs the result to another kafka stream
[ ] Configure logstash to fetch and persist data in the Elasticsearch database
[ ] Setup a kafka monitoring dashboard in prometheus or landoop
[ ] Implement a Apache spark job, which process data from kafka
[ ] Implement a Apache spark job, which uses grpahix
[ ] Implement a python stream processing job, which process the data using KSQL
